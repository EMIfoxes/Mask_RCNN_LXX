{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before step:tensor([[0.6614, 0.2669],\n",
      "        [0.0617, 0.6213]])\n",
      "weight after step:tensor([[-0.3386, -0.7331],\n",
      "        [-0.9383, -0.3787]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.optim as optim\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "setup_seed(1)  # 设置随机种子\n",
    " \n",
    "#构建可学习参数\n",
    "weight = torch.randn((2, 2), requires_grad=True)\n",
    "weight.grad = torch.ones((2, 2))\n",
    " \n",
    "#传入可学习参数，学习率设置为1\n",
    "optimizer = optim.SGD([weight], lr=1)\n",
    "\n",
    "# ----------------------------------- step -----------------------------------\n",
    "print(\"weight before step:{}\".format(weight.data))\n",
    "optimizer.step()        # 修改lr=1 0.1观察结果\n",
    "print(\"weight after step:{}\".format(weight.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before step:tensor([[-0.3386, -0.7331],\n",
      "        [-0.9383, -0.3787]])\n",
      "weight after step:tensor([[-1.3386, -1.7331],\n",
      "        [-1.9383, -1.3787]])\n",
      "weight in optimizer:2435071410240\n",
      "weight in weight:2435071410240\n",
      "\n",
      "weight.grad is tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "\n",
      "after optimizer.zero_grad(), weight.grad is\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------- zero_grad -----------------------------------\n",
    "print(\"weight before step:{}\".format(weight.data))\n",
    "optimizer.step()        # 修改lr=1 0.1观察结果\n",
    "print(\"weight after step:{}\".format(weight.data))\n",
    " \n",
    "print(\"weight in optimizer:{}\\nweight in weight:{}\\n\".format(id(optimizer.param_groups[0]['params'][0]), id(weight)))\n",
    " \n",
    "print(\"weight.grad is {}\\n\".format(weight.grad))\n",
    "optimizer.zero_grad()\n",
    "print(\"after optimizer.zero_grad(), weight.grad is\\n{}\".format(weight.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer.param_groups is\n",
      "[{'params': [tensor([[-1.3386, -1.7331],\n",
      "        [-1.9383, -1.3787]], requires_grad=True)], 'lr': 1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None}]\n",
      "optimizer.param_groups is\n",
      "[{'params': [tensor([[-1.3386, -1.7331],\n",
      "        [-1.9383, -1.3787]], requires_grad=True)], 'lr': 1, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None}, {'params': [tensor([[-0.4519, -0.1661, -1.5228],\n",
      "        [ 0.3817, -1.0276, -0.5631],\n",
      "        [-0.8923, -0.0583, -0.1955]], requires_grad=True)], 'lr': 0.0001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None}]\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------- add_param_group -----------------------------------\n",
    "print(\"optimizer.param_groups is\\n{}\".format(optimizer.param_groups))\n",
    " \n",
    "w2 = torch.randn((3, 3), requires_grad=True)\n",
    " \n",
    "optimizer.add_param_group({\"params\": w2, 'lr': 0.0001})\n",
    " \n",
    "print(\"optimizer.param_groups is\\n{}\".format(optimizer.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_dict before step:\n",
      " {'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'params': [0]}]}\n",
      "state_dict after step:\n",
      " {'state': {0: {'momentum_buffer': tensor([[6.5132, 6.5132],\n",
      "        [6.5132, 6.5132]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'params': [0]}]}\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------- state_dict -----------------------------------\n",
    "import os\n",
    "weight = torch.randn((2, 2), requires_grad=True)\n",
    "weight.grad = torch.ones((2, 2))\n",
    "optimizer = optim.SGD([weight], lr=0.1, momentum=0.9)\n",
    "opt_state_dict = optimizer.state_dict()\n",
    " \n",
    "print(\"state_dict before step:\\n\", opt_state_dict)\n",
    " \n",
    "for i in range(10):\n",
    "    optimizer.step()\n",
    " \n",
    "print(\"state_dict after step:\\n\", optimizer.state_dict())\n",
    "#保存状态信息\n",
    "path = \"D:\\Learn\\deep-learning-for-image-processing-master\\pytorch_object_detection\\mask_rcnn\"\n",
    "torch.save(optimizer.state_dict(), os.path.join(path, \"optimizer_state_dict.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_dict before load state:\n",
      " {'state': {}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'params': [0]}]}\n",
      "state_dict after load state:\n",
      " {'state': {0: {'momentum_buffer': tensor([[6.5132, 6.5132],\n",
      "        [6.5132, 6.5132]])}}, 'param_groups': [{'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'params': [0]}]}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------load state_dict -----------------------------------\n",
    " \n",
    "optimizer = optim.SGD([weight], lr=0.1, momentum=0.9)\n",
    "state_dict = torch.load(os.path.join(path, \"optimizer_state_dict.pkl\"))\n",
    "\n",
    "print(\"state_dict before load state:\\n\", optimizer.state_dict())\n",
    "optimizer.load_state_dict(state_dict)\n",
    "print(\"state_dict after load state:\\n\", optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ gradient descent ------------------------------\n",
    "    #记录loss和迭代次数用来画loss曲线\n",
    "iter_rec, loss_rec, x_rec = list(), list(), list()\n",
    " \n",
    "lr = 0.5   # /1. /.5 /.2 /.1 /.125\n",
    "max_iteration = 4  # /1. 4     /.5 4   /.2 20 200\n",
    " \n",
    "for i in range(max_iteration):\n",
    " \n",
    "    y = func(x)\n",
    "    y.backward()\n",
    " \n",
    "    print(\"Iter:{}, X:{:8}, X.grad:{:8}, loss:{:10}\".format(\n",
    "        i, x.detach().numpy()[0], x.grad.detach().numpy()[0], y.item()))\n",
    " \n",
    "    x_rec.append(x.item())\n",
    " \n",
    "    x.data.sub_(lr * x.grad)    # x -= x.grad  数学表达式意义:  x = x - x.grad    # 0.5 0.2 0.1 0.125\n",
    "    x.grad.zero_()\n",
    " \n",
    "    iter_rec.append(i)\n",
    "    loss_rec.append(y.detach().numpy())\n",
    " \n",
    "    plt.subplot(121).plot(iter_rec, loss_rec, '-ro')\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss value\")\n",
    " \n",
    "    x_t = torch.linspace(-3, 3, 100)\n",
    "    y = func(x_t)\n",
    "    plt.subplot(122).plot(x_t.numpy(), y.numpy(), label=\"y = 4*x^2\")\n",
    "    plt.grid()\n",
    "    y_rec = [func(torch.tensor(i)).item() for i in x_rec]\n",
    "    plt.subplot(122).plot(x_rec, y_rec, '-ro')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
